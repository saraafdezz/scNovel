{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2dec895",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scanpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscanpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msc\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scanpy'"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ae1bede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = sc.read_csv('darmanis_label.csv',dtype=\"str\")\n",
    "adata = sc.read_csv(\"darmanis_counts.csv\")\n",
    "data = adata.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6be921c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 466 × 22088"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "eeb5a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size 466\n",
      "['\"OPC\"' '\"astrocytes\"' '\"endothelial\"' '\"fetal_quiescent\"'\n",
      " '\"fetal_replicating\"' '\"hybrid\"' '\"microglia\"' '\"neurons\"'\n",
      " '\"oligodendrocytes\"']\n",
      "Label \"OPC\": [18]\n",
      "Label \"astrocytes\": [62]\n",
      "Label \"endothelial\": [20]\n",
      "Label \"fetal_quiescent\": [110]\n",
      "Label \"fetal_replicating\": [25]\n",
      "Label \"hybrid\": [46]\n",
      "Label \"microglia\": [16]\n",
      "Label \"neurons\": [131]\n",
      "Label \"oligodendrocytes\": [38]\n",
      "[18, 62, 20, 110, 25, 46, 16, 131, 38]\n",
      "[ 18  62  20 110  25  46  16 131  38]\n",
      "6\n",
      "[6]\n",
      "['\"microglia\"']\n",
      "Rare Cell Name ['\"microglia\"']: [16]\n",
      "{'\"OPC\"': 0, '\"astrocytes\"': 1, '\"endothelial\"': 2, '\"fetal_quiescent\"': 3, '\"fetal_replicating\"': 4, '\"hybrid\"': 5, '\"neurons\"': 6, '\"oligodendrocytes\"': 7}\n",
      "{'\"OPC\"': 0, '\"astrocytes\"': 1, '\"endothelial\"': 2, '\"fetal_quiescent\"': 3, '\"fetal_replicating\"': 4, '\"hybrid\"': 5, '\"neurons\"': 6, '\"oligodendrocytes\"': 7, '\"microglia\"': 8}\n",
      "                               1/2-SBSRNA4  A1BG  A1BG-AS1  A1CF  A2LD1  \\\n",
      "GSM1658333_nochipID13.C75.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "GSM1658241_nochipID11.C23.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "GSM1657892_1772078217.C58.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "GSM1658096_nochipID3.C51.csv           0.0   0.0       0.0   0.0    0.0   \n",
      "GSM1658329_nochipID13.C68.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "...                                    ...   ...       ...   ...    ...   \n",
      "GSM1657953_1772078236.C57.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "GSM1658001_nochipID14.C89.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "GSM1657893_1772078217.C59.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "GSM1658221_nochipID10.C58.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "GSM1657932_1772078236.C17.csv          0.0   0.0       0.0   0.0    0.0   \n",
      "\n",
      "                                    A2M  A2ML1  A2MP1  A4GALT  A4GNT  ...  \\\n",
      "GSM1658333_nochipID13.C75.csv  0.000000    0.0    0.0     0.0    0.0  ...   \n",
      "GSM1658241_nochipID11.C23.csv  0.000000    0.0    0.0     0.0    0.0  ...   \n",
      "GSM1657892_1772078217.C58.csv  0.431371    0.0    0.0     0.0    0.0  ...   \n",
      "GSM1658096_nochipID3.C51.csv   0.006104    0.0    0.0     0.0    0.0  ...   \n",
      "GSM1658329_nochipID13.C68.csv  0.042518    0.0    0.0     0.0    0.0  ...   \n",
      "...                                 ...    ...    ...     ...    ...  ...   \n",
      "GSM1657953_1772078236.C57.csv  0.000000    0.0    0.0     0.0    0.0  ...   \n",
      "GSM1658001_nochipID14.C89.csv  0.000000    0.0    0.0     0.0    0.0  ...   \n",
      "GSM1657893_1772078217.C59.csv  0.000000    0.0    0.0     0.0    0.0  ...   \n",
      "GSM1658221_nochipID10.C58.csv  0.000000    0.0    0.0     0.0    0.0  ...   \n",
      "GSM1657932_1772078236.C17.csv  0.000000    0.0    0.0     0.0    0.0  ...   \n",
      "\n",
      "                                   ZXDC  ZYG11A    ZYG11B       ZYX     ZZEF1  \\\n",
      "GSM1658333_nochipID13.C75.csv  0.000000     0.0  0.573165  0.000000  0.000000   \n",
      "GSM1658241_nochipID11.C23.csv  0.084571     0.0  0.000000  0.000000  0.199364   \n",
      "GSM1657892_1772078217.C58.csv  0.000000     0.0  0.000000  0.000000  0.000000   \n",
      "GSM1658096_nochipID3.C51.csv   0.000000     0.0  0.000000  0.120952  0.059423   \n",
      "GSM1658329_nochipID13.C68.csv  0.000000     0.0  0.000000  0.000000  0.000000   \n",
      "...                                 ...     ...       ...       ...       ...   \n",
      "GSM1657953_1772078236.C57.csv  0.000000     0.0  0.000000  0.000000  0.000000   \n",
      "GSM1658001_nochipID14.C89.csv  0.007640     0.0  0.695477  0.000000  0.000000   \n",
      "GSM1657893_1772078217.C59.csv  0.368908     0.0  0.000000  0.000000  0.000000   \n",
      "GSM1658221_nochipID10.C58.csv  0.296198     0.0  0.000000  0.000000  0.000000   \n",
      "GSM1657932_1772078236.C17.csv  0.426836     0.0  1.071282  0.000000  0.385598   \n",
      "\n",
      "                                   ZZZ3  alignment_not_unique  ambiguous  \\\n",
      "GSM1658333_nochipID13.C75.csv  0.000000              7.806736   3.452831   \n",
      "GSM1658241_nochipID11.C23.csv  0.000000              7.690265   3.558956   \n",
      "GSM1657892_1772078217.C58.csv  0.000000              7.876671   3.155754   \n",
      "GSM1658096_nochipID3.C51.csv   0.000000              8.334865   3.733182   \n",
      "GSM1658329_nochipID13.C68.csv  0.915695              7.574617   3.430451   \n",
      "...                                 ...                   ...        ...   \n",
      "GSM1657953_1772078236.C57.csv  0.000000              8.351960   4.593785   \n",
      "GSM1658001_nochipID14.C89.csv  0.000000              7.950789   2.389552   \n",
      "GSM1657893_1772078217.C59.csv  0.004200              7.962542   3.031871   \n",
      "GSM1658221_nochipID10.C58.csv  0.000000              7.735628   3.322121   \n",
      "GSM1657932_1772078236.C17.csv  0.000000              8.059197   3.622148   \n",
      "\n",
      "                               no_feature  tAKR  \n",
      "GSM1658333_nochipID13.C75.csv    8.503521   0.0  \n",
      "GSM1658241_nochipID11.C23.csv    8.656400   0.0  \n",
      "GSM1657892_1772078217.C58.csv    8.195053   0.0  \n",
      "GSM1658096_nochipID3.C51.csv     7.694880   0.0  \n",
      "GSM1658329_nochipID13.C68.csv    8.643412   0.0  \n",
      "...                                   ...   ...  \n",
      "GSM1657953_1772078236.C57.csv    8.009161   0.0  \n",
      "GSM1658001_nochipID14.C89.csv    8.679995   0.0  \n",
      "GSM1657893_1772078217.C59.csv    8.579595   0.0  \n",
      "GSM1658221_nochipID10.C58.csv    8.650831   0.0  \n",
      "GSM1657932_1772078236.C17.csv    8.233345   0.0  \n",
      "\n",
      "[337 rows x 22088 columns]\n",
      "                  Label\n",
      "134   \"fetal_quiescent\"\n",
      "72    \"fetal_quiescent\"\n",
      "160  \"oligodendrocytes\"\n",
      "350       \"endothelial\"\n",
      "130   \"fetal_quiescent\"\n",
      "..                  ...\n",
      "221           \"neurons\"\n",
      "10            \"neurons\"\n",
      "161               \"OPC\"\n",
      "52    \"fetal_quiescent\"\n",
      "200        \"astrocytes\"\n",
      "\n",
      "[337 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "def build_dataset(adata_this,label_this,drop_number=1):\n",
    "\n",
    "\n",
    "\n",
    "    adata=adata_this\n",
    "    # sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    # sc.pp.log1p(adata)\n",
    "    label=label_this.to_df()\n",
    "\n",
    "    print(\"Dataset Size {}\".format(len(adata)))\n",
    "\n",
    "    assert len(adata)==len(label),\"Data Length {} Does not Match Label Length {}\".format(len(adata),len(label))\n",
    "\n",
    "    set_label=np.unique(label.values)\n",
    "    print(set_label)\n",
    "\n",
    "    #Find the rare cell class\n",
    "    count=[]\n",
    "    for label_index in range(len(set_label)):\n",
    "        # print(label.values==set_label[label_index])\n",
    "        sum_number=sum(label.values==set_label[label_index])\n",
    "        count.append(sum_number[0])\n",
    "        print(\"Label {}: {}\".format(set_label[label_index],sum_number))\n",
    "    print(count)\n",
    "    print(np.array(count))\n",
    "    print(np.argmin(count))\n",
    "    min_index=np.argsort(count)[:drop_number]\n",
    "    print(min_index)\n",
    "    min_label=[]\n",
    "    for i in min_index:\n",
    "        min_label.append(set_label[i])\n",
    "    print(min_label)\n",
    "    print(\"Rare Cell Name {}: {}\".format(min_label,[count[count_i] for count_i in min_index]))\n",
    "\n",
    "    # Build Class Mapping for cell class\n",
    "    label_map={}\n",
    "    count_map=0\n",
    "    for label_index in range(len(set_label)):\n",
    "        if not label_index in min_index:\n",
    "            label_map[set_label[label_index]]=count_map\n",
    "            count_map+=1\n",
    "    print(label_map)\n",
    "    count_map_temp=count_map\n",
    "    for label_index in range(len(set_label)):\n",
    "        if label_index in min_index:\n",
    "            label_map[set_label[label_index]]=count_map_temp\n",
    "            count_map_temp+=1\n",
    "    # label_map[min_label]=count_map\n",
    "    print(label_map)\n",
    "\n",
    "    test_extract_ood = label.isin(min_label)\n",
    "    label_ood = label.loc[test_extract_ood.values]\n",
    "    X_test_ood=adata.loc[test_extract_ood.values]\n",
    "    # print(label_ood.values[0])\n",
    "    adata_id = adata.loc[~test_extract_ood.values]\n",
    "    label_id = label.loc[~test_extract_ood.values]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(adata_id,label_id,random_state=42,stratify=label_id)\n",
    "    print(X_train)\n",
    "    print(y_train)\n",
    "    return X_train,X_test,y_train,y_test,X_test_ood,label_ood\n",
    "X_train,X_test,y_train,y_test,X_test_ood,label_ood=build_dataset(data,label,drop_number=1)\n",
    "true_label=np.zeros(len(X_test)+len(X_test_ood))\n",
    "true_label[:len(X_test)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2f77b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 2 0 0 3 0 1 4 3 0 5 0 0 0 0 4 1 6 1 7 0 5 7 7 3 1 7 5 5 5 0 0 1 1 1\n",
      " 5 4 3 5 5 2 5 0 0 3 1 4 0 3 4 0 0 1 3 5 3 3 6 5 0 3 7 4 0 5 5 7 5 2 7 0 5\n",
      " 6 5 3 5 4 0 5 2 5 2 4 2 3 0 3 3 5 0 0 5 5 6 7 3 5 2 5 5 5 5 4 0 0 5 6 3 5\n",
      " 3 3 6 3 7 0 3 5 3 0 7 0 5 0 5 0 1 0 1 0 5 7 0 7 3 5 0 0 1 5 0 2 1 5 4 1 7\n",
      " 0 5 0 0 5 2 5 0 3 2 4 5 5 1 0 7 4 3 6 7 3 0 4 5 1 4 6 0 2 5 5 0 5 5 0 1 0\n",
      " 4 7 3 7 0 5 3 7 5 3 0 5 3 1 5 1 0 1 0 0 3 0 7 3 7 6 1 5 1 0 5 5 3 7 0 1 5\n",
      " 0 0 2 5 3 3 5 5 5 5 6 7 0 5 3 5 7 0 5 5 5 5 7 3 5 0 7 5 1 5 7 5 0 4 5 5 2\n",
      " 0 7 0 0 5 0 5 0 5 3 5 5 0 6 3 3 4 2 5 0 7 3 4 7 0 4 5 1 5 3 6 5 1 0 5 5 7\n",
      " 1 5 5 6 5 3 5 5 5 0 3 5 7 5 0 3 1 5 5 7 0 0 0 0 5 5 2 7 7 5 5 0 3 0 0 0 5\n",
      " 5 6 0 3]\n"
     ]
    }
   ],
   "source": [
    "# label.columns = ['Label']\n",
    "y_train.Label.value_counts()\n",
    "status_dict = y_train['Label'].unique().tolist()\n",
    "y_train['transfromed']=y_train['Label'].apply(lambda x : status_dict.index(x))\n",
    "label_arr = y_train['transfromed'].values\n",
    "print(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3cbcd959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8f4905b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b3708f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 0, 0, 3, 0, 1, 4, 3, 0, 5, 0, 0, 0, 0, 4, 1, 6, 1, 7,\n",
       "       0, 5, 7, 7, 3, 1, 7, 5, 5, 5, 0, 0, 1, 1, 1, 5, 4, 3, 5, 5, 2, 5,\n",
       "       0, 0, 3, 1, 4, 0, 3, 4, 0, 0, 1, 3, 5, 3, 3, 6, 5, 0, 3, 7, 4, 0,\n",
       "       5, 5, 7, 5, 2, 7, 0, 5, 6, 5, 3, 5, 4, 0, 5, 2, 5, 2, 4, 2, 3, 0,\n",
       "       3, 3, 5, 0, 0, 5, 5, 6, 7, 3, 5, 2, 5, 5, 5, 5, 4, 0, 0, 5, 6, 3,\n",
       "       5, 3, 3, 6, 3, 7, 0, 3, 5, 3, 0, 7, 0, 5, 0, 5, 0, 1, 0, 1, 0, 5,\n",
       "       7, 0, 7, 3, 5, 0, 0, 1, 5, 0, 2, 1, 5, 4, 1, 7, 0, 5, 0, 0, 5, 2,\n",
       "       5, 0, 3, 2, 4, 5, 5, 1, 0, 7, 4, 3, 6, 7, 3, 0, 4, 5, 1, 4, 6, 0,\n",
       "       2, 5, 5, 0, 5, 5, 0, 1, 0, 4, 7, 3, 7, 0, 5, 3, 7, 5, 3, 0, 5, 3,\n",
       "       1, 5, 1, 0, 1, 0, 0, 3, 0, 7, 3, 7, 6, 1, 5, 1, 0, 5, 5, 3, 7, 0,\n",
       "       1, 5, 0, 0, 2, 5, 3, 3, 5, 5, 5, 5, 6, 7, 0, 5, 3, 5, 7, 0, 5, 5,\n",
       "       5, 5, 7, 3, 5, 0, 7, 5, 1, 5, 7, 5, 0, 4, 5, 5, 2, 0, 7, 0, 0, 5,\n",
       "       0, 5, 0, 5, 3, 5, 5, 0, 6, 3, 3, 4, 2, 5, 0, 7, 3, 4, 7, 0, 4, 5,\n",
       "       1, 5, 3, 6, 5, 1, 0, 5, 5, 7, 1, 5, 5, 6, 5, 3, 5, 5, 5, 0, 3, 5,\n",
       "       7, 5, 0, 3, 1, 5, 5, 7, 0, 0, 0, 0, 5, 5, 2, 7, 7, 5, 5, 0, 3, 0,\n",
       "       0, 0, 5, 5, 6, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6118866e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 82, 1: 29, 2: 15, 3: 46, 4: 19, 5: 98, 6: 14, 7: 34})"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "495db1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e00f3f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Label\n",
      "355          \"neurons\"\n",
      "450  \"fetal_quiescent\"\n",
      "301           \"hybrid\"\n",
      "128  \"fetal_quiescent\"\n",
      "12   \"fetal_quiescent\"\n",
      "..                 ...\n",
      "422       \"astrocytes\"\n",
      "210          \"neurons\"\n",
      "227          \"neurons\"\n",
      "341          \"neurons\"\n",
      "343      \"endothelial\"\n",
      "\n",
      "[113 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "Counter(y_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c693b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dtype = torch.float\n",
    "\n",
    "# print(X_train)\n",
    "# X_train=torch.from_numpy(X_train.to_numpy())\n",
    "# X_test=torch.from_numpy(X_test.to_numpy())\n",
    "# print(X_test)\n",
    "# print(y_train)\n",
    "# y_train = torch.from_numpy(label_arr)\n",
    "test_data_typical = Data.TensorDataset(X_test, torch.zeros(len(X_test)))\n",
    "test_data_novel = Data.TensorDataset(torch.from_numpy(X_test_ood.to_numpy()), torch.zeros(len(X_test_ood)))\n",
    "test_data=torch.utils.data.ConcatDataset([test_data_typical, test_data_novel])\n",
    "test_loader = Data.DataLoader(dataset=test_data,\n",
    "                               batch_size=128,\n",
    "                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "210f94fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 2, 0, 0, 3, 0, 1, 4, 3, 0, 5, 0, 0, 0, 0, 4, 1, 6, 1, 7, 0, 5,\n",
      "        7, 7, 3, 1, 7, 5, 5, 5, 0, 0, 1, 1, 1, 5, 4, 3, 5, 5, 2, 5, 0, 0, 3, 1,\n",
      "        4, 0, 3, 4, 0, 0, 1, 3, 5, 3, 3, 6, 5, 0, 3, 7, 4, 0, 5, 5, 7, 5, 2, 7,\n",
      "        0, 5, 6, 5, 3, 5, 4, 0, 5, 2, 5, 2, 4, 2, 3, 0, 3, 3, 5, 0, 0, 5, 5, 6,\n",
      "        7, 3, 5, 2, 5, 5, 5, 5, 4, 0, 0, 5, 6, 3, 5, 3, 3, 6, 3, 7, 0, 3, 5, 3,\n",
      "        0, 7, 0, 5, 0, 5, 0, 1, 0, 1, 0, 5, 7, 0, 7, 3, 5, 0, 0, 1, 5, 0, 2, 1,\n",
      "        5, 4, 1, 7, 0, 5, 0, 0, 5, 2, 5, 0, 3, 2, 4, 5, 5, 1, 0, 7, 4, 3, 6, 7,\n",
      "        3, 0, 4, 5, 1, 4, 6, 0, 2, 5, 5, 0, 5, 5, 0, 1, 0, 4, 7, 3, 7, 0, 5, 3,\n",
      "        7, 5, 3, 0, 5, 3, 1, 5, 1, 0, 1, 0, 0, 3, 0, 7, 3, 7, 6, 1, 5, 1, 0, 5,\n",
      "        5, 3, 7, 0, 1, 5, 0, 0, 2, 5, 3, 3, 5, 5, 5, 5, 6, 7, 0, 5, 3, 5, 7, 0,\n",
      "        5, 5, 5, 5, 7, 3, 5, 0, 7, 5, 1, 5, 7, 5, 0, 4, 5, 5, 2, 0, 7, 0, 0, 5,\n",
      "        0, 5, 0, 5, 3, 5, 5, 0, 6, 3, 3, 4, 2, 5, 0, 7, 3, 4, 7, 0, 4, 5, 1, 5,\n",
      "        3, 6, 5, 1, 0, 5, 5, 7, 1, 5, 5, 6, 5, 3, 5, 5, 5, 0, 3, 5, 7, 5, 0, 3,\n",
      "        1, 5, 5, 7, 0, 0, 0, 0, 5, 5, 2, 7, 7, 5, 5, 0, 3, 0, 0, 0, 5, 5, 6, 0,\n",
      "        3])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 3.4528, 8.5035, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.5590, 8.6564, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.1558, 8.1951, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.0319, 8.5796, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.3221, 8.6508, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 3.6221, 8.2333, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(X_train)\n",
    "# X_train=torch.from_numpy(X_train.to_numpy())\n",
    "train_data= Data.TensorDataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "93f30e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "\n",
    "def Weighted_Sampling(train_label = None):\n",
    "\n",
    "    '''\n",
    "\n",
    "    :param train_label: Input train label (in tensor) to calculate sampling weight\n",
    "    :return: Pytorch Weighted Sampler\n",
    "    '''\n",
    "\n",
    "    class_sample_count = torch.tensor(\n",
    "        [(train_label == t).sum() for t in torch.unique(train_label, sorted=True)])\n",
    "\n",
    "    weight = 1. / class_sample_count.float()\n",
    "    samples_weight = torch.tensor([weight[t] for t in train_label])\n",
    "\n",
    "    sampler = Data.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    \n",
    "    return samples_weight, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0a7add23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 2, 0, 0, 3, 0, 1, 4, 3, 0, 5, 0, 0, 0, 0, 4, 1, 6, 1, 7, 0, 5,\n",
      "        7, 7, 3, 1, 7, 5, 5, 5, 0, 0, 1, 1, 1, 5, 4, 3, 5, 5, 2, 5, 0, 0, 3, 1,\n",
      "        4, 0, 3, 4, 0, 0, 1, 3, 5, 3, 3, 6, 5, 0, 3, 7, 4, 0, 5, 5, 7, 5, 2, 7,\n",
      "        0, 5, 6, 5, 3, 5, 4, 0, 5, 2, 5, 2, 4, 2, 3, 0, 3, 3, 5, 0, 0, 5, 5, 6,\n",
      "        7, 3, 5, 2, 5, 5, 5, 5, 4, 0, 0, 5, 6, 3, 5, 3, 3, 6, 3, 7, 0, 3, 5, 3,\n",
      "        0, 7, 0, 5, 0, 5, 0, 1, 0, 1, 0, 5, 7, 0, 7, 3, 5, 0, 0, 1, 5, 0, 2, 1,\n",
      "        5, 4, 1, 7, 0, 5, 0, 0, 5, 2, 5, 0, 3, 2, 4, 5, 5, 1, 0, 7, 4, 3, 6, 7,\n",
      "        3, 0, 4, 5, 1, 4, 6, 0, 2, 5, 5, 0, 5, 5, 0, 1, 0, 4, 7, 3, 7, 0, 5, 3,\n",
      "        7, 5, 3, 0, 5, 3, 1, 5, 1, 0, 1, 0, 0, 3, 0, 7, 3, 7, 6, 1, 5, 1, 0, 5,\n",
      "        5, 3, 7, 0, 1, 5, 0, 0, 2, 5, 3, 3, 5, 5, 5, 5, 6, 7, 0, 5, 3, 5, 7, 0,\n",
      "        5, 5, 5, 5, 7, 3, 5, 0, 7, 5, 1, 5, 7, 5, 0, 4, 5, 5, 2, 0, 7, 0, 0, 5,\n",
      "        0, 5, 0, 5, 3, 5, 5, 0, 6, 3, 3, 4, 2, 5, 0, 7, 3, 4, 7, 0, 4, 5, 1, 5,\n",
      "        3, 6, 5, 1, 0, 5, 5, 7, 1, 5, 5, 6, 5, 3, 5, 5, 5, 0, 3, 5, 7, 5, 0, 3,\n",
      "        1, 5, 5, 7, 0, 0, 0, 0, 5, 5, 2, 7, 7, 5, 5, 0, 3, 0, 0, 0, 5, 5, 6, 0,\n",
      "        3])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "weight, sampler = Weighted_Sampling(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "467ea1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0122, 0.0122, 0.0345, 0.0667, 0.0122, 0.0122, 0.0217, 0.0122, 0.0345,\n",
       "        0.0526, 0.0217, 0.0122, 0.0102, 0.0122, 0.0122, 0.0122, 0.0122, 0.0526,\n",
       "        0.0345, 0.0714, 0.0345, 0.0294, 0.0122, 0.0102, 0.0294, 0.0294, 0.0217,\n",
       "        0.0345, 0.0294, 0.0102, 0.0102, 0.0102, 0.0122, 0.0122, 0.0345, 0.0345,\n",
       "        0.0345, 0.0102, 0.0526, 0.0217, 0.0102, 0.0102, 0.0667, 0.0102, 0.0122,\n",
       "        0.0122, 0.0217, 0.0345, 0.0526, 0.0122, 0.0217, 0.0526, 0.0122, 0.0122,\n",
       "        0.0345, 0.0217, 0.0102, 0.0217, 0.0217, 0.0714, 0.0102, 0.0122, 0.0217,\n",
       "        0.0294, 0.0526, 0.0122, 0.0102, 0.0102, 0.0294, 0.0102, 0.0667, 0.0294,\n",
       "        0.0122, 0.0102, 0.0714, 0.0102, 0.0217, 0.0102, 0.0526, 0.0122, 0.0102,\n",
       "        0.0667, 0.0102, 0.0667, 0.0526, 0.0667, 0.0217, 0.0122, 0.0217, 0.0217,\n",
       "        0.0102, 0.0122, 0.0122, 0.0102, 0.0102, 0.0714, 0.0294, 0.0217, 0.0102,\n",
       "        0.0667, 0.0102, 0.0102, 0.0102, 0.0102, 0.0526, 0.0122, 0.0122, 0.0102,\n",
       "        0.0714, 0.0217, 0.0102, 0.0217, 0.0217, 0.0714, 0.0217, 0.0294, 0.0122,\n",
       "        0.0217, 0.0102, 0.0217, 0.0122, 0.0294, 0.0122, 0.0102, 0.0122, 0.0102,\n",
       "        0.0122, 0.0345, 0.0122, 0.0345, 0.0122, 0.0102, 0.0294, 0.0122, 0.0294,\n",
       "        0.0217, 0.0102, 0.0122, 0.0122, 0.0345, 0.0102, 0.0122, 0.0667, 0.0345,\n",
       "        0.0102, 0.0526, 0.0345, 0.0294, 0.0122, 0.0102, 0.0122, 0.0122, 0.0102,\n",
       "        0.0667, 0.0102, 0.0122, 0.0217, 0.0667, 0.0526, 0.0102, 0.0102, 0.0345,\n",
       "        0.0122, 0.0294, 0.0526, 0.0217, 0.0714, 0.0294, 0.0217, 0.0122, 0.0526,\n",
       "        0.0102, 0.0345, 0.0526, 0.0714, 0.0122, 0.0667, 0.0102, 0.0102, 0.0122,\n",
       "        0.0102, 0.0102, 0.0122, 0.0345, 0.0122, 0.0526, 0.0294, 0.0217, 0.0294,\n",
       "        0.0122, 0.0102, 0.0217, 0.0294, 0.0102, 0.0217, 0.0122, 0.0102, 0.0217,\n",
       "        0.0345, 0.0102, 0.0345, 0.0122, 0.0345, 0.0122, 0.0122, 0.0217, 0.0122,\n",
       "        0.0294, 0.0217, 0.0294, 0.0714, 0.0345, 0.0102, 0.0345, 0.0122, 0.0102,\n",
       "        0.0102, 0.0217, 0.0294, 0.0122, 0.0345, 0.0102, 0.0122, 0.0122, 0.0667,\n",
       "        0.0102, 0.0217, 0.0217, 0.0102, 0.0102, 0.0102, 0.0102, 0.0714, 0.0294,\n",
       "        0.0122, 0.0102, 0.0217, 0.0102, 0.0294, 0.0122, 0.0102, 0.0102, 0.0102,\n",
       "        0.0102, 0.0294, 0.0217, 0.0102, 0.0122, 0.0294, 0.0102, 0.0345, 0.0102,\n",
       "        0.0294, 0.0102, 0.0122, 0.0526, 0.0102, 0.0102, 0.0667, 0.0122, 0.0294,\n",
       "        0.0122, 0.0122, 0.0102, 0.0122, 0.0102, 0.0122, 0.0102, 0.0217, 0.0102,\n",
       "        0.0102, 0.0122, 0.0714, 0.0217, 0.0217, 0.0526, 0.0667, 0.0102, 0.0122,\n",
       "        0.0294, 0.0217, 0.0526, 0.0294, 0.0122, 0.0526, 0.0102, 0.0345, 0.0102,\n",
       "        0.0217, 0.0714, 0.0102, 0.0345, 0.0122, 0.0102, 0.0102, 0.0294, 0.0345,\n",
       "        0.0102, 0.0102, 0.0714, 0.0102, 0.0217, 0.0102, 0.0102, 0.0102, 0.0122,\n",
       "        0.0217, 0.0102, 0.0294, 0.0102, 0.0122, 0.0217, 0.0345, 0.0102, 0.0102,\n",
       "        0.0294, 0.0122, 0.0122, 0.0122, 0.0122, 0.0102, 0.0102, 0.0667, 0.0294,\n",
       "        0.0294, 0.0102, 0.0102, 0.0122, 0.0217, 0.0122, 0.0122, 0.0122, 0.0102,\n",
       "        0.0102, 0.0714, 0.0122, 0.0217])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "76f94500",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= Data.DataLoader(dataset=train_data,batch_size=32,sampler = sampler,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "1bc32e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scNovel import classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "051a83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_class = len(status_dict)\n",
    "iteration=3000\n",
    "count_iteration=0\n",
    "\n",
    "model = classifier(input_size, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "0477ec81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier(\n",
      "  (layer1): Linear(in_features=22088, out_features=128, bias=True)\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (elu1): ELU(alpha=1.0)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (elu2): ELU(alpha=1.0)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (layer3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (elu3): ELU(alpha=1.0)\n",
      "  (dropout3): Dropout(p=0.1, inplace=False)\n",
      "  (layer4): Linear(in_features=32, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "edaea553",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d46433ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7e98a886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Start annotating----------\n",
      "Computational unit be used is: cuda\n",
      "Finish 11.0/3000\n",
      "Finish 22.0/3000\n",
      "Finish 33.0/3000\n",
      "Finish 44.0/3000\n",
      "Finish 55.0/3000\n",
      "Finish 66.0/3000\n",
      "Finish 77.0/3000\n",
      "Finish 88.0/3000\n",
      "Finish 99.0/3000\n",
      "Finish 110.0/3000\n",
      "Finish 121.0/3000\n",
      "Finish 132.0/3000\n",
      "Finish 143.0/3000\n",
      "Finish 154.0/3000\n",
      "Finish 165.0/3000\n",
      "Finish 176.0/3000\n",
      "Finish 187.0/3000\n",
      "Finish 198.0/3000\n",
      "Finish 209.0/3000\n",
      "Finish 220.0/3000\n",
      "Finish 231.0/3000\n",
      "Finish 242.0/3000\n",
      "Finish 253.0/3000\n",
      "Finish 264.0/3000\n",
      "Finish 275.0/3000\n",
      "Finish 286.0/3000\n",
      "Finish 297.0/3000\n",
      "Finish 308.0/3000\n",
      "Finish 319.0/3000\n",
      "Finish 330.0/3000\n",
      "Finish 341.0/3000\n",
      "Finish 352.0/3000\n",
      "Finish 363.0/3000\n",
      "Finish 374.0/3000\n",
      "Finish 385.0/3000\n",
      "Finish 396.0/3000\n",
      "Finish 407.0/3000\n",
      "Finish 418.0/3000\n",
      "Finish 429.0/3000\n",
      "Finish 440.0/3000\n",
      "Finish 451.0/3000\n",
      "Finish 462.0/3000\n",
      "Finish 473.0/3000\n",
      "Finish 484.0/3000\n",
      "Finish 495.0/3000\n",
      "Finish 506.0/3000\n",
      "Finish 517.0/3000\n",
      "Finish 528.0/3000\n",
      "Finish 539.0/3000\n",
      "Finish 550.0/3000\n",
      "Finish 561.0/3000\n",
      "Finish 572.0/3000\n",
      "Finish 583.0/3000\n",
      "Finish 594.0/3000\n",
      "Finish 605.0/3000\n",
      "Finish 616.0/3000\n",
      "Finish 627.0/3000\n",
      "Finish 638.0/3000\n",
      "Finish 649.0/3000\n",
      "Finish 660.0/3000\n",
      "Finish 671.0/3000\n",
      "Finish 682.0/3000\n",
      "Finish 693.0/3000\n",
      "Finish 704.0/3000\n",
      "Finish 715.0/3000\n",
      "Finish 726.0/3000\n",
      "Finish 737.0/3000\n",
      "Finish 748.0/3000\n",
      "Finish 759.0/3000\n",
      "Finish 770.0/3000\n",
      "Finish 781.0/3000\n",
      "Finish 792.0/3000\n",
      "Finish 803.0/3000\n",
      "Finish 814.0/3000\n",
      "Finish 825.0/3000\n",
      "Finish 836.0/3000\n",
      "Finish 847.0/3000\n",
      "Finish 858.0/3000\n",
      "Finish 869.0/3000\n",
      "Finish 880.0/3000\n",
      "Finish 891.0/3000\n",
      "Finish 902.0/3000\n",
      "Finish 913.0/3000\n",
      "Finish 924.0/3000\n",
      "Finish 935.0/3000\n",
      "Finish 946.0/3000\n",
      "Finish 957.0/3000\n",
      "Finish 968.0/3000\n",
      "Finish 979.0/3000\n",
      "Finish 990.0/3000\n",
      "Finish 1001.0/3000\n",
      "Finish 1012.0/3000\n",
      "Finish 1023.0/3000\n",
      "Finish 1034.0/3000\n",
      "Finish 1045.0/3000\n",
      "Finish 1056.0/3000\n",
      "Finish 1067.0/3000\n",
      "Finish 1078.0/3000\n",
      "Finish 1089.0/3000\n",
      "Finish 1100.0/3000\n",
      "Finish 1111.0/3000\n",
      "Finish 1122.0/3000\n",
      "Finish 1133.0/3000\n",
      "Finish 1144.0/3000\n",
      "Finish 1155.0/3000\n",
      "Finish 1166.0/3000\n",
      "Finish 1177.0/3000\n",
      "Finish 1188.0/3000\n",
      "Finish 1199.0/3000\n",
      "Finish 1210.0/3000\n",
      "Finish 1221.0/3000\n",
      "Finish 1232.0/3000\n",
      "Finish 1243.0/3000\n",
      "Finish 1254.0/3000\n",
      "Finish 1265.0/3000\n",
      "Finish 1276.0/3000\n",
      "Finish 1287.0/3000\n",
      "Finish 1298.0/3000\n",
      "Finish 1309.0/3000\n",
      "Finish 1320.0/3000\n",
      "Finish 1331.0/3000\n",
      "Finish 1342.0/3000\n",
      "Finish 1353.0/3000\n",
      "Finish 1364.0/3000\n",
      "Finish 1375.0/3000\n",
      "Finish 1386.0/3000\n",
      "Finish 1397.0/3000\n",
      "Finish 1408.0/3000\n",
      "Finish 1419.0/3000\n",
      "Finish 1430.0/3000\n",
      "Finish 1441.0/3000\n",
      "Finish 1452.0/3000\n",
      "Finish 1463.0/3000\n",
      "Finish 1474.0/3000\n",
      "Finish 1485.0/3000\n",
      "Finish 1496.0/3000\n",
      "Finish 1507.0/3000\n",
      "Finish 1518.0/3000\n",
      "Finish 1529.0/3000\n",
      "Finish 1540.0/3000\n",
      "Finish 1551.0/3000\n",
      "Finish 1562.0/3000\n",
      "Finish 1573.0/3000\n",
      "Finish 1584.0/3000\n",
      "Finish 1595.0/3000\n",
      "Finish 1606.0/3000\n",
      "Finish 1617.0/3000\n",
      "Finish 1628.0/3000\n",
      "Finish 1639.0/3000\n",
      "Finish 1650.0/3000\n",
      "Finish 1661.0/3000\n",
      "Finish 1672.0/3000\n",
      "Finish 1683.0/3000\n",
      "Finish 1694.0/3000\n",
      "Finish 1705.0/3000\n",
      "Finish 1716.0/3000\n",
      "Finish 1727.0/3000\n",
      "Finish 1738.0/3000\n",
      "Finish 1749.0/3000\n",
      "Finish 1760.0/3000\n",
      "Finish 1771.0/3000\n",
      "Finish 1782.0/3000\n",
      "Finish 1793.0/3000\n",
      "Finish 1804.0/3000\n",
      "Finish 1815.0/3000\n",
      "Finish 1826.0/3000\n",
      "Finish 1837.0/3000\n",
      "Finish 1848.0/3000\n",
      "Finish 1859.0/3000\n",
      "Finish 1870.0/3000\n",
      "Finish 1881.0/3000\n",
      "Finish 1892.0/3000\n",
      "Finish 1903.0/3000\n",
      "Finish 1914.0/3000\n",
      "Finish 1925.0/3000\n",
      "Finish 1936.0/3000\n",
      "Finish 1947.0/3000\n",
      "Finish 1958.0/3000\n",
      "Finish 1969.0/3000\n",
      "Finish 1980.0/3000\n",
      "Finish 1991.0/3000\n",
      "Finish 2002.0/3000\n",
      "Finish 2013.0/3000\n",
      "Finish 2024.0/3000\n",
      "Finish 2035.0/3000\n",
      "Finish 2046.0/3000\n",
      "Finish 2057.0/3000\n",
      "Finish 2068.0/3000\n",
      "Finish 2079.0/3000\n",
      "Finish 2090.0/3000\n",
      "Finish 2101.0/3000\n",
      "Finish 2112.0/3000\n",
      "Finish 2123.0/3000\n",
      "Finish 2134.0/3000\n",
      "Finish 2145.0/3000\n",
      "Finish 2156.0/3000\n",
      "Finish 2167.0/3000\n",
      "Finish 2178.0/3000\n",
      "Finish 2189.0/3000\n",
      "Finish 2200.0/3000\n",
      "Finish 2211.0/3000\n",
      "Finish 2222.0/3000\n",
      "Finish 2233.0/3000\n",
      "Finish 2244.0/3000\n",
      "Finish 2255.0/3000\n",
      "Finish 2266.0/3000\n",
      "Finish 2277.0/3000\n",
      "Finish 2288.0/3000\n",
      "Finish 2299.0/3000\n",
      "Finish 2310.0/3000\n",
      "Finish 2321.0/3000\n",
      "Finish 2332.0/3000\n",
      "Finish 2343.0/3000\n",
      "Finish 2354.0/3000\n",
      "Finish 2365.0/3000\n",
      "Finish 2376.0/3000\n",
      "Finish 2387.0/3000\n",
      "Finish 2398.0/3000\n",
      "Finish 2409.0/3000\n",
      "Finish 2420.0/3000\n",
      "Finish 2431.0/3000\n",
      "Finish 2442.0/3000\n",
      "Finish 2453.0/3000\n",
      "Finish 2464.0/3000\n",
      "Finish 2475.0/3000\n",
      "Finish 2486.0/3000\n",
      "Finish 2497.0/3000\n",
      "Finish 2508.0/3000\n",
      "Finish 2519.0/3000\n",
      "Finish 2530.0/3000\n",
      "Finish 2541.0/3000\n",
      "Finish 2552.0/3000\n",
      "Finish 2563.0/3000\n",
      "Finish 2574.0/3000\n",
      "Finish 2585.0/3000\n",
      "Finish 2596.0/3000\n",
      "Finish 2607.0/3000\n",
      "Finish 2618.0/3000\n",
      "Finish 2629.0/3000\n",
      "Finish 2640.0/3000\n",
      "Finish 2651.0/3000\n",
      "Finish 2662.0/3000\n",
      "Finish 2673.0/3000\n",
      "Finish 2684.0/3000\n",
      "Finish 2695.0/3000\n",
      "Finish 2706.0/3000\n",
      "Finish 2717.0/3000\n",
      "Finish 2728.0/3000\n",
      "Finish 2739.0/3000\n",
      "Finish 2750.0/3000\n",
      "Finish 2761.0/3000\n",
      "Finish 2772.0/3000\n",
      "Finish 2783.0/3000\n",
      "Finish 2794.0/3000\n",
      "Finish 2805.0/3000\n",
      "Finish 2816.0/3000\n",
      "Finish 2827.0/3000\n",
      "Finish 2838.0/3000\n",
      "Finish 2849.0/3000\n",
      "Finish 2860.0/3000\n",
      "Finish 2871.0/3000\n",
      "Finish 2882.0/3000\n",
      "Finish 2893.0/3000\n",
      "Finish 2904.0/3000\n",
      "Finish 2915.0/3000\n",
      "Finish 2926.0/3000\n",
      "Finish 2937.0/3000\n",
      "Finish 2948.0/3000\n",
      "Finish 2959.0/3000\n",
      "Finish 2970.0/3000\n",
      "Finish 2981.0/3000\n",
      "Finish 2992.0/3000\n",
      "Finish 3000.0/3000\n",
      "\n",
      "--------Annotation Finished----------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"--------Start annotating----------\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if processing_unit == 'cpu':\n",
    "#     device = torch.device('cpu')\n",
    "# elif processing_unit == 'gpu':\n",
    "#     if torch.cuda.is_available():\n",
    "#         device = torch.device('cuda')\n",
    "#     else:\n",
    "#         device = torch.device('cpu')\n",
    "#         print(\"No GPUs are available on your server.\")\n",
    "\n",
    "print(\"Computational unit be used is:\", device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "while count_iteration<iteration:\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_x)\n",
    "        train_loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        count_iteration+=1\n",
    "        if count_iteration>=iteration:\n",
    "            break\n",
    "    print(\"Finish {}/{}\".format(float(count_iteration),iteration))\n",
    "    # a = \"=\" * (count_iteration + 1)\n",
    "    # b = \".\" * (iteration - count_iteration - 1)\n",
    "    # c = ((count_iteration + 1) / iteration) * 100\n",
    "    # dur = time.perf_counter() - start\n",
    "    # print(\"\\r{:^3.0f}%[{}->{}]{:.2f}s\".format(c, a, b, dur), end='')\n",
    "    # time.sleep(0.1)\n",
    "\n",
    "\n",
    "print(\"\\n--------Annotation Finished----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "38bc0cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9175884955752213\n"
     ]
    }
   ],
   "source": [
    "from scNovel.score_functions import get_ood_scores\n",
    "model.eval()\n",
    "score_function=\"sim\"\n",
    "\n",
    "test_score = get_ood_scores(test_loader, model, score_function, device=device)\n",
    "\n",
    "auroc=sklearn.metrics.roc_auc_score(true_label,test_score)\n",
    "print(auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "db35e0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228bca46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
